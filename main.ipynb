{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pickle as pk\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "import torch\n",
    "use_gpu = torch.cuda.is_available() and not os.environ['USE_CPU']\n",
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the DIV2K dataset\n",
    "div2k_train_dir = r'C:\\Users\\cl502_03\\Downloads\\image super-resolution\\DIV2K_train_HR'\n",
    "div2k_val_dir = r'C:\\Users\\cl502_03\\Downloads\\image super-resolution\\DIV2K_valid_HR'\n",
    "\n",
    "# Image dimensions\n",
    "input_shape = (1440, 2560, 3)\n",
    "\n",
    "# Load DIV2K images\n",
    "def load_div2k_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = load_img(os.path.join(directory, filename), target_size=input_shape)\n",
    "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "x_train = load_div2k_images(div2k_train_dir)\n",
    "x_val = load_div2k_images(div2k_val_dir)\n",
    "\n",
    "with open(\"x_train.pkl\", \"wb\") as file:\n",
    "    pk.dump(x_train, file)\n",
    "\n",
    "with open(\"x_val.pkl\", \"wb\") as file:\n",
    "    pk.dump(x_val, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1440, 2560, 3)\n",
    "with open(\"x_train.pkl\", \"rb\") as file:\n",
    "    x_train = pk.load(file)\n",
    "\n",
    "# Load x_val from the binary file\n",
    "with open(\"x_val.pkl\", \"rb\") as file:\n",
    "    x_val = pk.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "51/51 [==============================] - 3416s 67s/step - loss: 0.0189 - val_loss: 0.0048\n",
      "Epoch 2/2\n",
      "51/51 [==============================] - 3258s 64s/step - loss: 0.0036 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20e8b1ef790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple SRCNN model (you can replace this with a more advanced model)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(64, (9, 9), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.Conv2D(32, (1, 1), activation='relu', padding='same'),\n",
    "    layers.Conv2D(3, (5, 5), padding='same'),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, x_train, epochs=2, batch_size=16, validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\cl502_03\\Downloads\\image super-resolution\\model1.h5\n"
     ]
    }
   ],
   "source": [
    "model_path = r'C:\\Users\\cl502_03\\Downloads\\image super-resolution\\model1.h5'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'model1.h5'\n",
    "input_shape = (1080, 1920, 3)\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 719ms/step\n",
      "Super-resolution complete.\n"
     ]
    }
   ],
   "source": [
    "# Use the model for super-resolution\n",
    "input_image = load_img(r\"0801.png\", target_size=input_shape)\n",
    "input_image_array = img_to_array(input_image) / 255.0  # Normalize to [0, 1]\n",
    "input_image_array = np.expand_dims(input_image_array, axis=0)  # Add batch dimension\n",
    "\n",
    "super_res_image = model.predict(input_image_array)\n",
    "\n",
    "# Save the super-resolved image\n",
    "super_res_image = array_to_img(super_res_image[0])\n",
    "super_res_image.save(r'car_1080_1920.png')\n",
    "\n",
    "print(\"Super-resolution complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
